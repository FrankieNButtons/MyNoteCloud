# 填空题汇总
1. Hadoop默认的块大小为`128MB`
2. Spark使用`Scala`语言开发
3. Hadoop使用`Java`语言开发
4. Hadoop的资源管理器是`Yarn`（全称为`Yet Another Resource Negotiator`）
5. Hadoop的分布式文件系统是`HDFS`
6. Hadoop的计算框架是`MapReduce`
 7. Hadoop的基本计算单元是`Split`
 8. MapReduce的Shuffle过程分为`Partition`、`Sort`和`Merge`三个阶段
 9. Scala中的Unit类型相当于`void`类型
 10. NameNode的作用是`协调集群中的数据存储（存储元数据）`
 11. Scala中的数值类型总共有Byte，Short，Int，Long，Float，Double，Char
 12. DataNode的作用是`存储拆分后的数据块`
 13.  `val lst10 = List(1, 2, 3, 4, 5), println(lst10.foldLeft(0)((x, y) => x - y))`的结果为`-15`（0-1-2-3-4-5=-15）
 14.  `val lst10 = List(1, 2, 3, 4, 5), println(lst10.foldRight(0)((x, y)=> x - y))`的结果为`3`（5-(4-(3-(2-(1-0))))=3）
 15. Spark中RDD的创建方式有`Paralize`和`makeRDD`
 16. Spark运行速度比MapReduce快的原因是`内存计算`和`DAG优化`
 17.  MapReduce中Mapper执行map方法的次数等于Split的`行数`
 18. RDD的全称是Resilient Distributed Dataset，即`弹性分布式数据集`
 19. HDFS得罪一小存储单位叫`Block`
 20. MapReduce适合PB级以上数据的`离线`处理
 21. PySpark使用RDD从整数数组`rdd = sc.paralize([10, 27, 65, 22, 82, 86, 75])`取出偶数并乘以2：`rdd.filter(lambda x: x % 2 == 0).map(lambda x: x * 2).collect()`
 22. 21的功能使用Scala实现
 23. RDD与其父RDD有`窄依赖`和`宽依赖`两种依赖
 24. Spark Streaming使用`微批次`的架构把流处理变为连续小规模批处理
 25. Storm的开发语言是`Conjure`
 26. Kalfka集群包含一个或多个服务器，这种服务器被称为`Broker`
 27. 分布式消息系统有两种主要的信息传递模式`点对点`和`发布-订阅`
 28. Scala-Shell中直接对DataFrame执行隐式的向RDD的转换需要导入spark中的`implicit_`模块（`import spark.implicits._`）
 29. 
 30. 
