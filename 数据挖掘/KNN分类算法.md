# KNN分类算法
## 一、KNN算法原理（投票机制）
 1. 训练数据集：训练数据集包含n个样本，每个样本包含m个特征值，每个特征值是一个实数。
 2. 测试数据集：测试数据集包含m个特征值，每个特征值是一个实数。
 3. 测试数据集的每个样本与训练数据集中的每个样本进行距离计算。
 4. 选取距离最近的k个（k可指定）样本，根据这些样本的类别，确定测试数据集的类别。
 5. 常用的距离函数有欧式距离、曼哈顿距离、切比雪夫距离等。
   - 欧式距离：$$d(x,y)=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}$$
   - 曼哈顿距离：$$d(x,y)=\sum_{i=1}^n|x_i-y_i|$$
   - 切比雪夫距离：$$d(x,y)=\max_{i=1}^n|x_i-y_i|$$
   - 闵可夫斯基距离：$$d(x,y)=\left(\sum_{i=1}^n|x_i-y_i|^p\right)^{\frac{1}{p}}$$
   - 余弦相似度：$$d(x,y)=\frac{\sum_{i=1}^nx_iy_i}{\sqrt{\sum_{i=1}^nx_i^2}\sqrt{\sum_{i=1}^ny_i^2}}$$
   - 皮尔逊相关系数：$$d(x,y)=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}$$
## 特殊KNN算法：最近邻算法（k=1）

