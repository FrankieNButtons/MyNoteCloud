# 基于规则的决策树模型

## 1. 决策树的介绍
### 1.1 规则解释
1. 决策树是一种树形结构，用来对未知数据进行分类的算法。
2. 决策树算法的优点：
 1. 简单，容易理解，便于程序化处理。
 2. 容易处理缺失值。
 3. 容易处理非结构化数据。
5. 缺点：
 1. 容易欠拟合。
 2. 容易过拟合。






### 1.2 决策准则
1. ID3算法
   - 信息增益：
   \[ent = -\sum_{i=1}^{n}p_{i}\log_{2}p_{i}\]
1. C4.5算法
   - 信息增益率：
   \[\]
2. CART算法
   -





### 剪枝
#### 最小错误率剪枝

#### 



#### 分类回归树的交叉验证剪枝


## R语言实现
使用的核心R包为`rpart`和`rpart.plot`
### 基本使用
1. 安装包：`install.packages("rpart")`
2. 导入包：`library(rpart)`
3. 调用函数：`rpart(y~x, data=Data, method, parms=list(split=type), control=obj)`
**参数介绍**
   -  `y`: 目标变量
   -  `x`: 输入变量
   -  `data`: 数据集
   -  `method`: 模型类型，可选`class`和`anova`，默认为`anova`
   -  `parms`: 参数，包括`split`，可选`"best"`, `"rsq"`, `"gini"`, `"ext"`, `"costs"`, `"rpart"`，默认为`"best"`
   -  `control`: 控制参数，包括`minsplit`，`minbucket`，`maxcompete`，`xval`，默认为`list(minsplit=20, minbucket=10)`
   -  `xval`: 交叉验证次数，默认为0，不进行交叉验证
### 实例

```R

```